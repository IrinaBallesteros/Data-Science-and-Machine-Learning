{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"surface_hoar\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"fresh_thickness\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"weak_layers\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"no_visitors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a simple logistic regression model\n",
    "# Here we import a function that splits datasets according to a given ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using our model\n",
    "# predict to get a probability\n",
    "\n",
    "# get first 3 samples from dataset\n",
    "samples = test[\"weak_layers\"][:4]\n",
    "\n",
    "# use the model to get predictions as possibilities\n",
    "estimated_probabilities = model.predict(samples)\n",
    "\n",
    "# Print results for each sample\n",
    "for sample, pred in zip(samples,estimated_probabilities):\n",
    "    print(f\"A weak_layer with value {sample} yields a {pred * 100:.2f}% chance of an avalanche.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "# Show a graph of the result\n",
    "predict = lambda x: model.predict(pandas.DataFrame({\"weak_layers\": x}))\n",
    "\n",
    "graphing.line_2D([(\"Model\", predict)],\n",
    "                 x_range=[-20,40],\n",
    "                 label_x=\"weak_layers\", \n",
    "                 label_y=\"estimated probability of an avalanche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum number of weak layers:\", min(train.weak_layers))\n",
    "print(\"Maximum number of weak layers:\", max(train.weak_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get actual rates of avalanches at 0 years\n",
    "avalanche_outcomes_for_0_layers = train[train.weak_layers == 0].avalanche\n",
    "print(\"Average rate of avalanches for 0 weak layers of snow\", np.average(avalanche_outcomes_for_0_layers))\n",
    "\n",
    "# Get actual rates of avalanches at 10 years\n",
    "avalanche_outcomes_for_10_layers = train[train.weak_layers == 10].avalanche\n",
    "print(\"Average rate of avalanches for 10 weak layers of snow\", np.average(avalanche_outcomes_for_10_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification or decision thresholds\n",
    "# threshold to get an absolute value\n",
    "threshold = 0.5\n",
    "\n",
    "# Add classification to the samples we used before\n",
    "for sample, pred in list(zip(samples,estimated_probabilities)):\n",
    "    print(f\"A weak_layer with value {sample} yields a chance of {pred * 100:.2f}% of an avalanche. Classification = {pred > threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance on test set\n",
    "# Classify the mdel predictions using the threshold\n",
    "predictions = model.predict(test) > threshold\n",
    "\n",
    "# Compare the predictions to the actual outcomes in the dataset\n",
    "accuracy = np.average(predictions == test.avalanche)\n",
    "\n",
    "# Print the evaluation\n",
    "print(f\"The model correctly predicted outcomes {accuracy * 100:.2f}% of time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data and the relationship we're going to model\n",
    "print(dataset.head())\n",
    "\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"weak_layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 75/25 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.25, random_state=10)\n",
    "\n",
    "print(\"Train size:\", train.shape[0])\n",
    "print(\"Test size:\", test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting a model\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing the model with summary information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing model visually\n",
    "def predict(weak_layers):\n",
    "    return model.predict(dict(weak_layers=weak_layers))\n",
    "\n",
    "graphing.scatter_2D(test, label_x=\"weak_layers\", label_y=\"avalanche\", trendline=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing.scatter_2D(test, label_x=\"weak_layers\", label_y=\"avalanche\", x_range=[-20,20], trendline=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess with cost function\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Make predictions from the test set\n",
    "predictions = model.predict(test)\n",
    "\n",
    "# Calculate log loss\n",
    "print(\"Log loss\", log_loss(test.avalanche, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess accuracy\n",
    "\n",
    "import numpy\n",
    "\n",
    "# Print a few predictions before we convert them to categories\n",
    "print(f\"First three predictions (probabilities): {predictions.iloc[0]}, {predictions.iloc[1]}, {predictions.iloc[2]}\")\n",
    "\n",
    "# convert to absolute values\n",
    "avalanche_predicted = predictions >= 0.5\n",
    "\n",
    "# Print a few predictions converted into categories\n",
    "print(f\"First three predictions (categories): {avalanche_predicted.iloc[0]}, {avalanche_predicted.iloc[1]}, {avalanche_predicted.iloc[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what proportion were predicted correctly\n",
    "guess_was_correct = test.avalanche == avalanche_predicted\n",
    "accuracy = numpy.average(guess_was_correct)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy for whole test dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative: calculate how often it guessed no avalanche when one actually occurred\n",
    "false_negative = numpy.average(numpy.logical_not(guess_was_correct) & test.avalanche)\n",
    "\n",
    "# False positive: calculate how often it guessed avalanche, when none actually happened\n",
    "false_positive = numpy.average(numpy.logical_not(guess_was_correct) & numpy.logical_not(test.avalanche))\n",
    "\n",
    "\n",
    "print(f\"Wrongly predicted an avalanche {false_positive * 100}% of the time\")\n",
    "print(f\"Failed to predict avalanches {false_negative * 100}% of the time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise: Improving a logistic regression model\n",
    "#Data visualisation\n",
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\", index_col=0)\n",
    "\n",
    "# Split our data into training and test\n",
    "import sklearn.model_selection\n",
    "train, test = sklearn.model_selection.train_test_split(dataset, test_size=0.25, random_state=10)\n",
    "\n",
    "print(\"Train size:\", train.shape[0])\n",
    "print(\"Test size:\", test.shape[0])\n",
    "\n",
    "#Let's have a look at the data\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple logistic regression\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(model):\n",
    "    '''\n",
    "    Calculates accuracy\n",
    "    '''\n",
    "    # Make estimations and convert to categories\n",
    "    avalanche_predicted = model.predict(test) > 0.5\n",
    "\n",
    "    # Calculate what proportion were predicted correctly\n",
    "    # We can use sklearn to calculate accuracy for us\n",
    "    print(\"Accuracy:\", accuracy_score(test.avalanche, avalanche_predicted))\n",
    "\n",
    "calculate_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizing multiple features\n",
    "# Perform logistic regression.\n",
    "model_all_features = smf.logit(\"avalanche ~ weak_layers + surface_hoar + fresh_thickness + wind + no_visitors + tracked_out\", train).fit()\n",
    "calculate_accuracy(model_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplifying our model\n",
    "# Perform logistic regression.\n",
    "model_simplified = smf.logit(\"avalanche ~ weak_layers + surface_hoar + wind + no_visitors\", train).fit()\n",
    "calculate_accuracy(model_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Careful feature selection\n",
    "model_all_features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with an interaction. Notice the end of the string where\n",
    "# we've a multiply sign between no_visitors and fresh_thickness\n",
    "formula = \"avalanche ~ weak_layers + surface_hoar + wind + no_visitors * fresh_thickness\"\n",
    "model_with_interaction = smf.logit(formula, train).fit()\n",
    "calculate_accuracy(model_with_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_interaction.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions with multiple features\n",
    "graphing.model_to_surface_plot(model_with_interaction, [\"weak_layers\", \"wind\"], test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing.model_to_surface_plot(model_with_interaction, [\"no_visitors\", \"fresh_thickness\"], test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
